{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T20:27:07.565832Z",
     "start_time": "2024-04-21T20:27:02.179958Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzrMR2xp7cy4"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T20:27:07.949040Z",
     "start_time": "2024-04-21T20:27:07.568169Z"
    },
    "executionInfo": {
     "elapsed": 718,
     "status": "ok",
     "timestamp": 1645090204779,
     "user": {
      "displayName": "TFM TFM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08251762647272837249"
     },
     "user_tz": -60
    },
    "id": "5pm7duy4y6WU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import logging\n",
    "import statistics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Reshape, UpSampling2D, MaxPooling2D, add\n",
    "from tensorflow.keras.layers import SeparableConv2D, Conv2DTranspose, Dense, Conv2D\n",
    "from tensorflow.keras.layers import ReLU, Dropout, BatchNormalization, Flatten, Activation\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow import device\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99fQIfRY7ZyJ"
   },
   "source": [
    "# Enviroment set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T20:27:07.954273Z",
     "start_time": "2024-04-21T20:27:07.951734Z"
    }
   },
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T20:28:12.384059Z",
     "start_time": "2024-04-21T20:28:12.378868Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGES_PATH = ''\n",
    "LOG_PATH = ''\n",
    "\n",
    "logging.basicConfig(filename=LOG_PATH + \"std.log\", \n",
    "                    format='%(asctime)s %(message)s', \n",
    "                    filemode='w')\n",
    "logger=logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T20:28:13.112157Z",
     "start_time": "2024-04-21T20:28:13.106625Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mean_loss(loss, n_batches):\n",
    "    num_epochs = int(len(loss)/n_batches)\n",
    "    mean_loss = []\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        mean_loss.append(statistics.mean(loss[i*n_batches:(i+1)*n_batches]))\n",
    "        \n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T20:28:13.471877Z",
     "start_time": "2024-04-21T20:28:13.467441Z"
    }
   },
   "outputs": [],
   "source": [
    "def shuffle_four_arrays(a, b, c, d):\n",
    "    assert len(a) == len(b) and len(a) == len(c) and len(a) == len(d)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p], c[p], d[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHQtQpKeTgLq"
   },
   "source": [
    "# Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T20:28:14.415341Z",
     "start_time": "2024-04-21T20:28:14.331505Z"
    }
   },
   "outputs": [],
   "source": [
    "class cbir_cnn():\n",
    "\n",
    "    def __init__(self):\n",
    "        # Training configuration\n",
    "        self.n_epochs = 25\n",
    "        self.batch_size = 32\n",
    "        self.n_batches = 0\n",
    "        self.ev_interval_1 = 100\n",
    "        self.ev_interval_2 = 20000\n",
    "        self.conf_mat_samples = 100\n",
    "        \n",
    "        # Training data\n",
    "        self.epoch = 0\n",
    "        self.batch = 0\n",
    "        self.val_perc = 0.1\n",
    "        \n",
    "        # Image dimensions\n",
    "        self.img_height =  240\n",
    "        self.img_width = 240\n",
    "        self.img_channels = 4\n",
    "        \n",
    "        # Networks configuration\n",
    "        self.filters_encoder = [16, 32, 64, 128, 256]\n",
    "        self.filters_decoder = [256, 128, 64, 32, 16]\n",
    "        \n",
    "        self.classifier_perceptron = [64]\n",
    "\n",
    "        self.latent_dim = 500\n",
    "        \n",
    "        # Dataset\n",
    "        self.X_train = None\n",
    "        self.X_seg_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "        self.X_val = None\n",
    "        self.X_seg_val = None\n",
    "        self.y_val = None\n",
    "        \n",
    "        self.sub_id_train = None\n",
    "        self.tumour_area_train = None\n",
    "        self.sub_id_val = None\n",
    "        self.tumour_area_val = None\n",
    "        \n",
    "        # Models\n",
    "        self.encoder = None\n",
    "        self.autoencoder = None\n",
    "        self.classifier = None\n",
    "        self.composed_model = None\n",
    "        \n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'loss' : [],\n",
    "            'val_loss' : [],\n",
    "            'loss_mean' : [],\n",
    "            'loss_epoch' : [],\n",
    "\n",
    "            'reconstruction_output_loss' : [],\n",
    "            'val_reconstruction_output_loss' : [],\n",
    "            'reconstruction_output_loss_mean' : [],\n",
    "            'reconstruction_output_loss_epoch' : [],\n",
    "\n",
    "            'classification_output_loss' : [],\n",
    "            'val_classification_output_loss' : [],\n",
    "            'classification_output_loss_mean' : [],\n",
    "            'classification_output_loss_epoch' : [],\n",
    "        }\n",
    "    \n",
    "    #### LOAD BRATS DATA FROM ####\n",
    "    def load_data(self):\n",
    "        X_load = []\n",
    "        X_seg_load = []\n",
    "        y_load = []\n",
    "        sub_id_load = []\n",
    "        tumour_area = []\n",
    "\n",
    "        for i, folder_path in enumerate(glob.glob(IMAGES_PATH + '/*')):\n",
    "            if i%75==0:\n",
    "                print(str(i) + ' folders loaded')\n",
    "\n",
    "            id = folder_path[-3:]\n",
    "\n",
    "            for img_path in glob.glob(folder_path + '/*flair*.png'):\n",
    "                img = Image.open(img_path)\n",
    "                img_array = np.array(img)\n",
    "                img_array = np.expand_dims(img_array, axis=0)\n",
    "                \n",
    "                img_array = np.append(img_array, [np.array(Image.open(img_path[:81] + 't1' + img_path[-8:]))], axis=0)\n",
    "                img_array = np.append(img_array, [np.array(Image.open(img_path[:81] + 't1ce' + img_path[-8:]))], axis=0)\n",
    "                img_array = np.append(img_array, [np.array(Image.open(img_path[:81] + 't2' + img_path[-8:]))], axis=0)\n",
    "                \n",
    "                img_array = np.rollaxis(img_array, 0, 3)\n",
    "                X_load.append(img_array)\n",
    "                \n",
    "                path = img_path[:81] + 'hemi' + img_path[-8:]\n",
    "                if os.path.exists(path):\n",
    "                    img = Image.open(path)\n",
    "                    img_array = np.array(img)\n",
    "                    X_seg_load.append(img_array)\n",
    "                else:\n",
    "                    X_seg_load.append(None)\n",
    "\n",
    "                y_path = img_path[:81] + 'seg' + img_path[-8:]\n",
    "                img = Image.open(y_path)\n",
    "                img_array = np.array(img)\n",
    "                y_load.append(img_array)\n",
    "\n",
    "                sub_id_load.append(id)\n",
    "                tumour_area.append(self.get_tum_area(img_array))\n",
    "\n",
    "        # Input image scanner\n",
    "        X_train_aux = np.asarray(X_load[int(self.val_perc * len(X_load)):])\n",
    "        X_train_aux = X_train_aux/127.5 - 1\n",
    "        self.X_train = X_train_aux\n",
    "        \n",
    "        X_val_aux = np.asarray(X_load[:int(self.val_perc * len(X_load))])\n",
    "        X_val_aux = X_val_aux/127.5 - 1\n",
    "        self.X_val = X_val_aux\n",
    "        \n",
    "        # Segmented anatomical labels\n",
    "        X_seg_train_aux = np.asarray(X_seg_load[int(self.val_perc * len(X_seg_load)):])\n",
    "        self.X_seg_train = X_seg_train_aux\n",
    "        \n",
    "        X_seg_val_aux = np.asarray(X_seg_load[:int(self.val_perc * len(X_seg_load))])\n",
    "        self.X_seg_val = X_seg_val_aux\n",
    "        \n",
    "        # Tumour presence labels\n",
    "        y_train_aux = np.asarray(y_load[int(self.val_perc * len(y_load)):])\n",
    "        y_train_aux = y_train_aux/64\n",
    "        self.y_train = y_train_aux\n",
    "        \n",
    "        y_val_aux = np.asarray(y_load[:int(self.val_perc * len(y_load))])\n",
    "        y_val_aux = y_val_aux/64\n",
    "        self.y_val = y_val_aux\n",
    "        \n",
    "        # Patient id\n",
    "        self.sub_id_train = np.asarray(sub_id_load[int(self.val_perc * len(sub_id_load)):])\n",
    "        self.sub_id_val = np.asarray(sub_id_load[:int(self.val_perc * len(sub_id_load))])\n",
    "        \n",
    "        # Tumoural area\n",
    "        self.tumour_area_train = np.asarray(tumour_area[int(self.val_perc * len(tumour_area)):])\n",
    "        self.tumour_area_val = np.asarray(tumour_area[:int(self.val_perc * len(tumour_area))])\n",
    "    \n",
    "    def load_labels(self, y):\n",
    "        labels = []\n",
    "        for img in y:\n",
    "            if np.amax(img) > 0:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "                \n",
    "        return np.asarray(labels)\n",
    "    \n",
    "    def get_tum_area(self, img_array):\n",
    "        return np.count_nonzero(img_array > 0)\n",
    "    \n",
    "    #### NETWORK GENERATION ####\n",
    "    \n",
    "    def create_res_block(self, input_layer, filters, kernel_size):\n",
    "        x = input_layer\n",
    "        for i in range(2):\n",
    "            x = BatchNormalization()(x)\n",
    "            x = ReLU()(x)\n",
    "            x = Dropout(0.3)(x)\n",
    "            x = SeparableConv2D(filters, kernel_size=kernel_size, strides=1, padding=\"same\")(x)\n",
    "\n",
    "        # Match num of filters\n",
    "        y = SeparableConv2D(filters, kernel_size=(1,1), strides=1, padding=\"same\")(input_layer)\n",
    "            \n",
    "        x = add([x, y])\n",
    "        return x\n",
    "    \n",
    "    def create_encoder(self, input_img):\n",
    "        x = input_img\n",
    "        \n",
    "        # Downsize layers\n",
    "        for i in range(len(self.filters_encoder)):\n",
    "            if i != 0:\n",
    "                x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "            x = self.create_res_block(x, self.filters_encoder[i], kernel_size=3)\n",
    "\n",
    "        # Latent dimension      \n",
    "        x = Flatten()(x)\n",
    "        x = Dense(self.latent_dim)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        return x\n",
    "    \n",
    "    def create_decoder(self, latent_space):\n",
    "        # From latent space to image\n",
    "        x = Dense(15*15*256)(latent_space)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Reshape((15, 15, 256))(x)\n",
    "\n",
    "        # Upsampling layers\n",
    "        for i in range(len(self.filters_decoder)):\n",
    "            if i != 0:\n",
    "                x = UpSampling2D(2)(x)\n",
    "            x = self.create_res_block(x, self.filters_decoder[i], kernel_size=3)\n",
    "        \n",
    "        # Output image generation\n",
    "        x = SeparableConv2D(self.img_channels, kernel_size=1, strides=1, padding=\"same\",\n",
    "                            activation='tanh', name='reconstruction_output')(x)\n",
    "        return x\n",
    "    \n",
    "    def create_classifier(self, latent_dim):\n",
    "        # Perceptron layers\n",
    "        x = Flatten()(latent_dim)\n",
    "        \n",
    "        for n_neurons in self.classifier_perceptron:\n",
    "            x = Dense(n_neurons)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = ReLU()(x)\n",
    "            x = Dropout(0.3)(x)\n",
    "\n",
    "        # Classification\n",
    "        x = Dense(1, activation='sigmoid', name='classification_output')(x)\n",
    "        return x\n",
    "    \n",
    "    def create_models(self):\n",
    "        input_img = Input(shape=(self.img_height,\n",
    "                                 self.img_width,\n",
    "                                 self.img_channels))\n",
    "\n",
    "        # Encoder generation\n",
    "        latent_space = self.create_encoder(input_img)\n",
    "        self.encoder = Model(input_img, latent_space)\n",
    "\n",
    "        # Decoder generation\n",
    "        output_img = self.create_decoder(latent_space)\n",
    "        self.autoencoder = Model(input_img, output_img)\n",
    "\n",
    "        # Classifier generation\n",
    "        classification = self.create_classifier(latent_space)\n",
    "        self.classifier = Model(input_img, classification)\n",
    "\n",
    "        # Ensemble generation\n",
    "        self.composed_model = Model(input_img, [output_img, classification])\n",
    "        \n",
    "    #### PLOTTING FUNCTIONS ####\n",
    "    \n",
    "    def plot_reconstruction(self, n_plots, original_imgs, reconstructed_img_predictions):\n",
    "        # Define figure\n",
    "        f, axarr = plt.subplots(n_plots, 2, figsize=(8, 3*n_plots))\n",
    "        plt.suptitle('Epoch: ' + str(self.epoch) + ', Batch: ' + str(self.batch), fontsize=16)\n",
    "\n",
    "        axarr[0,0].set_title('Source image')\n",
    "        axarr[0,1].set_title('Reconstructed image')\n",
    "\n",
    "        # Plot each reconstruction\n",
    "        for i in range(n_plots):\n",
    "            axarr[i,0].imshow(original_imgs[i,:,:,0], cmap='gray')\n",
    "            axarr[i,1].imshow(reconstructed_img_predictions[i,:,:,0], cmap='gray')\n",
    "\n",
    "            axarr[i,0].get_xaxis().set_visible(False)\n",
    "            axarr[i,0].get_yaxis().set_visible(False)\n",
    "            axarr[i,1].get_xaxis().set_visible(False)\n",
    "            axarr[i,1].get_yaxis().set_visible(False)\n",
    "\n",
    "        # Save figure\n",
    "        plt.savefig(LOG_PATH + 'reconstructions/e' + str(self.epoch).zfill(3) + 'b'\n",
    "                    + str(self.batch).zfill(5) + '_reconstructed_image.png')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_train_val(self, loss_name=''):\n",
    "        # X axis definition\n",
    "        x_axis = range(len(self.history[loss_name + 'loss']))\n",
    "        x_axis_mean = range(0, len(self.history[loss_name + 'loss_mean']))\n",
    "\n",
    "        # Define figure\n",
    "        plt.rcParams['figure.figsize'] = [20, 5]\n",
    "        f, ax = plt.subplots(1, 2, sharex=False, sharey=False)\n",
    "        f.suptitle(loss_name)\n",
    "\n",
    "        # Plot complete loss figure\n",
    "        ax[0].plot(x_axis, self.history[loss_name + 'loss'], label='Train Loss')\n",
    "        ax[0].plot(x_axis, self.history['val_' + loss_name + 'loss'], label='Validation Loss')\n",
    "        ax[0].set_title('Loss')\n",
    "        ax[0].set_xlabel('iteration')\n",
    "        ax[0].legend(loc=\"upper right\")\n",
    "        ax[0].grid()\n",
    "\n",
    "        # Plot boxplot for each epoch figure\n",
    "        ax[1].plot(x_axis_mean, self.history[loss_name + 'loss_mean'])\n",
    "        ax[1].boxplot(self.history[loss_name + 'loss_epoch'], positions=x_axis_mean, showfliers=False)\n",
    "        ax[1].set_title('Mean Loss')\n",
    "        ax[1].set_xlabel('epoch')\n",
    "        ax[1].legend(loc=\"upper right\")\n",
    "        ax[1].grid()\n",
    "\n",
    "        # Save figure\n",
    "        plt.savefig(LOG_PATH + loss_name + 'train_losses.png')\n",
    "        plt.show()\n",
    "        \n",
    "    def get_mean_loss(self, loss_name):\n",
    "        n_batches = int(len(self.X_train) / self.batch_size)\n",
    "        \n",
    "        epoch_loss = np.split(np.array(self.history[loss_name]), int(len(np.array(self.history[loss_name]))/n_batches))\n",
    "        mean_loss = get_mean_loss(self.history[loss_name], n_batches)\n",
    "\n",
    "        self.history[loss_name + '_epoch'] = epoch_loss\n",
    "        self.history[loss_name + '_mean'] = mean_loss\n",
    "        \n",
    "    def conf_matrix(self, y_real, y_pred):\n",
    "        # Define figure\n",
    "        f, ax = plt.subplots(2, 1, figsize=(5, 10))\n",
    "        f.suptitle('Epoch: ' + str(self.epoch) + ', Batch: ' + str(self.batch), fontsize=16)\n",
    "\n",
    "        # Plot conf matrix for each class\n",
    "        conf_matrix = confusion_matrix(y_real, y_pred)\n",
    "        sns.heatmap(conf_matrix, annot=True,\n",
    "                    cmap='Blues', fmt = 'd', ax=ax[0], cbar=False)\n",
    "\n",
    "        ax[1].set_xlim((0,1))\n",
    "        ax[1].set_ylim((0,1))\n",
    "        ax[1].text(0.5, 0.5, classification_report(y_real, y_pred), ha='center', va='center')\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        # Save figure\n",
    "        plt.savefig(LOG_PATH + 'conf_matrix/e' + str(self.epoch).zfill(3) + 'b'\n",
    "                    + str(self.batch).zfill(5) + '_confusion_matrix.png')\n",
    "        plt.show()\n",
    "    \n",
    "    #### TRAINING ####\n",
    "    \n",
    "    def train(self):      \n",
    "        print('-----COMPILING MODEL-----')\n",
    "        losses = {\n",
    "            \"reconstruction_output\": \"mse\",\n",
    "            \"classification_output\": \"binary_crossentropy\",\n",
    "        }\n",
    "\n",
    "        loss_weights = {\n",
    "            \"reconstruction_output\": 0.2,\n",
    "            \"classification_output\": 0.8\n",
    "        }\n",
    "        \n",
    "        self.composed_model.compile(loss=losses, loss_weights=loss_weights,\n",
    "                                    optimizer=Adam()\n",
    "                                   )\n",
    "        \n",
    "        self.X_train, self.y_train, self.sub_id_train, self.tumour_area_train = shuffle_four_arrays(self.X_train, self.y_train,\n",
    "                                                                            self.sub_id_train, self.tumour_area_train)\n",
    "        self.X_val, self.y_val, self.sub_id_val, self.tumour_area_val = shuffle_four_arrays(self.X_val, self.y_val,\n",
    "                                                                            self.sub_id_val, self.tumour_area_val)\n",
    "        \n",
    "        print('-----TRAIN START-----')\n",
    "        with device('/GPU:1'):\n",
    "            for epoch in range(self.n_epochs):\n",
    "                self.epoch = epoch\n",
    "                logger.critical('='*5 + 'EPOCH ' + str(epoch)  + '='*5)\n",
    "                start = time.time()\n",
    "\n",
    "                n_batches = int(len(self.X_train) / self.batch_size)\n",
    "                print(n_batches)\n",
    "                for batch in range(n_batches):\n",
    "                    self.batch = batch\n",
    "                    X = self.X_train[batch*self.batch_size:(batch+1)*self.batch_size]\n",
    "                    y_imgs = self.y_train[batch*self.batch_size:(batch+1)*self.batch_size]\n",
    "                    y_labels = self.load_labels(y_imgs)\n",
    "                    \n",
    "                    losses = self.composed_model.train_on_batch(x=X,\n",
    "                                                                y={\"reconstruction_output\": X,\n",
    "                                                                   \"classification_output\": y_labels},\n",
    "                                                                return_dict=True)\n",
    "                    self.history['loss'].append(losses['loss'])\n",
    "                    self.history['reconstruction_output_loss'].append(losses['reconstruction_output_loss'])\n",
    "                    self.history['classification_output_loss'].append(losses['classification_output_loss'])\n",
    "                    \n",
    "                    idx = np.random.randint(0, len(self.X_val) / self.batch_size)\n",
    "                    X_val = self.X_val[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                    y_imgs = self.y_val[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                    y_labels = self.load_labels(y_imgs)\n",
    "                    \n",
    "                    val_losses = self.composed_model.test_on_batch(x=X_val,\n",
    "                                                               y={\"reconstruction_output\": X_val,\n",
    "                                                                  \"classification_output\": y_labels},\n",
    "                                                               return_dict=True)\n",
    "                    self.history['val_loss'].append(val_losses['loss'])\n",
    "                    self.history['val_reconstruction_output_loss'].append(val_losses['reconstruction_output_loss'])\n",
    "                    self.history['val_classification_output_loss'].append(val_losses['classification_output_loss'])\n",
    "\n",
    "                    if batch % self.ev_interval_1 == 0:\n",
    "                        logger.critical('Epoch: ' + str(self.epoch) +\n",
    "                                        ' \\tBatch ' + str(self.batch) + ': ' + str(losses))\n",
    "\n",
    "                    if batch % self.ev_interval_2 == 0:\n",
    "                        # Reconstruction evaluation\n",
    "                        n_plots = 3\n",
    "                        self.plot_reconstruction(n_plots, self.X_val[:n_plots],\n",
    "                                                 self.autoencoder.predict(self.X_val[:n_plots]))\n",
    "                        \n",
    "                        # Confusion matrix evaluation\n",
    "                        y_real_imgs = self.y_val[:self.conf_mat_samples]\n",
    "                        y_real = self.load_labels(y_real_imgs)\n",
    "                        y_pred = self.classifier.predict(self.X_val[:self.conf_mat_samples])\n",
    "                        self.conf_matrix(y_real, np.around(y_pred, 0))\n",
    "\n",
    "                self.get_mean_loss('loss')\n",
    "                self.get_mean_loss('reconstruction_output_loss')\n",
    "                self.get_mean_loss('classification_output_loss')\n",
    "\n",
    "                self.plot_train_val()\n",
    "                self.plot_train_val('reconstruction_output_')\n",
    "                self.plot_train_val('classification_output_')\n",
    "\n",
    "                end = time.time()\n",
    "                logger.critical('Epoch time ' + str(end-start))\n",
    "                start = time.time()\n",
    "                \n",
    "                # Saving models\n",
    "                logger.critical('Saving models')\n",
    "                self.encoder.save(LOG_PATH + 'models/e' + str(self.epoch).zfill(3) + '_encoder.h5')\n",
    "                self.autoencoder.save(LOG_PATH  + 'models/e' + str(self.epoch).zfill(3) + '_autoencoder.h5')\n",
    "                self.classifier.save(LOG_PATH  + 'models/e' + str(self.epoch).zfill(3) + '_classifier.h5')\n",
    "                self.composed_model.save(LOG_PATH  + 'models/e' + str(self.epoch).zfill(3) + '_composed_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T20:28:14.992164Z",
     "start_time": "2024-04-21T20:28:14.989291Z"
    }
   },
   "outputs": [],
   "source": [
    "cbir = cbir_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T20:28:32.604566Z",
     "start_time": "2024-04-21T20:28:15.476214Z"
    }
   },
   "outputs": [],
   "source": [
    "cbir.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T20:27:09.770723Z",
     "start_time": "2024-04-21T20:27:08.211277Z"
    }
   },
   "outputs": [],
   "source": [
    "cbir.create_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T20:27:12.060796Z",
     "start_time": "2024-04-21T20:27:09.772808Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(cbir.composed_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T20:27:12.482199Z",
     "start_time": "2024-04-21T20:27:12.063237Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cbir.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOWnpEtbtBYdwzbkV75yS8R",
   "collapsed_sections": [],
   "name": "Autoencoder CBIR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
